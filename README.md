# Named Entity Recognition using Hugging Face Transformers

## ğŸ“Œ Project Overview

This project demonstrates **Named Entity Recognition (NER)** using the [Hugging Face Transformers](https://huggingface.co/transformers/) library. It fine-tunes a pretrained BERT model (`bert-base-uncased`) on the **CoNLL-2003** dataset, which includes entities like persons, organizations, locations, and miscellaneous types.

### Key Highlights
- Uses `bert-base-uncased` for token classification
- Handles token-label alignment using `.word_ids()`
- Fine-tuned using Hugging Faceâ€™s `Trainer` API
- Evaluated using the `seqeval` metric

---

## ğŸ“‚ Dataset

- **Source**: [CoNLL-2003](https://huggingface.co/datasets/conll2003)
- **Access**: Automatically downloaded using `datasets.load_dataset('conll2003')`
- **Entity Types**: `PER`, `ORG`, `LOC`, `MISC`
- **Structure**: Token-level annotations for named entities

---

## ğŸ›  Installation

Install all required dependencies with:

```bash
pip install transformers datasets tokenizer seqeval evaluate accelerate
```

---

## ğŸ§  Model and Tokenization

- **Tokenizer**: `BertTokenizerFast` from `bert-base-uncased`
- Tokenization with `is_split_into_words=True` for word-level alignment
- Labels are aligned to subword tokens using a custom function:
  ```python
  def tokenize_and_align_label(examples, label_all_tokens=True):
      ...
  ```

---

## ğŸ‹ï¸ Training Configuration

- **Model**: `AutoModelForTokenClassification`  
- **Training Arguments**:
  - Epochs: `10`
  - Learning rate: `2e-5`
  - Batch size: `16` (train & eval)
  - Weight decay: `0.01`
  - Evaluation strategy: `"epoch"`

---

## ğŸ“Š Evaluation

- **Metric**: `seqeval` from Hugging Faceâ€™s `evaluate` library
- Calculates:
  - Precision
  - Recall
  - F1-score
- Evaluates for each individual entity type (e.g., PER, LOC, ORG)

---

## âœ… Sample Output

Example of token-label alignment:
```
Token: John            Label: B-PER
Token: lives           Label: O
Token: in              Label: O
Token: New             Label: B-LOC
Token: York            Label: I-LOC
```

---

## ğŸ“ File Structure

```bash
NER_using_huggingface_transformer/
â”œâ”€â”€ NER_using_huggingface_transformer.ipynb  # Main notebook
â””â”€â”€ README.md                                 # Project documentation
```

---

## ğŸš€ Future Work

- Upload and deploy model via Hugging Face Model Hub
- Add confusion matrices and per-class evaluation plots
- Explore CRF postprocessing for improved accuracy
- Train on custom NER datasets for domain-specific applications

---

## ğŸ™Œ Credits

- ğŸ¤— [Hugging Face](https://huggingface.co/) for `transformers`, `datasets`, `evaluate`
- ğŸ§  CoNLL-2003 for the NER dataset
- ğŸ”§ Libraries used: `NumPy`, `tokenizers`, `evaluate`, `seqeval`, `transformers`

---

